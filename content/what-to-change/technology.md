+++
content = ""
header_image = "/uploads/what-tech.jpg"
password_protected = true
show_sub_navigation = true
text_alignment = ""
title = "Technology"
[menu.footer]
parent = "What to change"
weight = 5
[menu.main]
parent = "What to change"
weight = 5
[[sections]]
content = "Tech companies operate on the cutting edge of innovation, and often venture into new product areas at a pace with which regulation cannot be expected to keep up. So it frequently falls to the companies themselves to act with care and prudence, and marshall against unforeseen consequences; something they have often failed to do.\n\nThe potential ethical issues that tech companies face are so varied and constantly shifting that they cannot all be listed here; what is most needed is for these companies to develop an [approach](https://www.scu.edu/ethics-in-technology-practice/ethical-toolkit/) to innovation with societal welfare at its heart. The [Ethical Explorer Pack](https://ethicalexplorer.org/) has been launched to help all tech workers - engineers, product managers, founders - to grapple with many of these issues."
template = "block-text"
[[sections]]
heading = "Privacy"
template = "block-heading"
[[sections]]
content = "We share and generate more information than ever before, leading to huge troves of sensitive data about each of us. This creates a range of potential risks about what companies do with that data, how they communicate the uses of that data with data subjects, and how that data is protected.\n\nSo far, many companies’ records on privacy issues have been pretty poor. Lengthy terms of service agreements have sought to insulate companies from risk while leaving them as unfettered as possible, while failing to inform consumers of how data would be used. Alongside these pervasive problems, huge data breaches at the likes of Equifax and Facebook have had disastrous consequences for millions of people.\n\nResolving privacy issues is more crucial now than ever, with new tools being developed to help contain the COVID-19 outbreak, as well as the increase in people working from home. As more sensitive data is collected, companies have a role to ensure this is done in an informed, safe and proportionate way."
template = "block-text"
[[sections]]
template = "block-faq"
title = ""
[[sections.faq]]
answer = "* How clearly does your company communicate with data subjects on how their data will be used? Are data subjects able to effectively limit sharing of their data?\n* What is your company’s policy on sharing data with third parties, including governments?\n* Are your companies’ policies different in jurisdictions where legal protections are weaker?"
question = "Some questions to start with"
[[sections.faq]]
answer = "_What you need to know_ - The Ranking Digital Rights (RDR) project has a detailed [chapter ](https://rankingdigitalrights.org/index2019/report/privacy/)on privacy, the various challenges attached to it and some recommendations for company action. For an alternative take, [Amnesty International](https://www.amnesty.org/en/documents/pol30/1404/2019/en/) looks specifically at Facebook and Google and the risks of their current approach to privacy.\n\n  \n_Who are the big contributors_ - RDR produces an annual [ranking](https://rankingdigitalrights.org/index2019/) of 24 large technology companies from around the world on their approach to privacy. In addition, Amazon’s Rekognition software has drawn significant [concern](https://www.aclunc.org/blog/amazon-teams-law-enforcement-deploy-dangerous-new-face-recognition-technology) around privacy issues."
question = "Further information"
[[sections]]
heading = "Content moderation"
template = "block-heading"
[[sections]]
image = "/uploads/what-tech-content-moderation.jpg"
template = "block-image"
[[sections]]
content = "The internet has given “anyone in the world the power to share anything with anyone”. While the enormous benefits of this should not be forgotten, it has led to a host of problems as well, including giving a platform to disinformation and disturbing content. And when this principle is not followed, it tends to be at the [behest](https://www.nytimes.com/2021/05/17/technology/apple-china-censorship-data.html) of authoritarian governments.\n\nThere are no simple solutions to these problems. While highly inappropriate content naturally needs to be policed and taken down, there is a clear [human cost](https://www.rottentomatoes.com/m/the_cleaners) to those responsible for this task. There are also free speech concerns, as something may be provocative and controversial without meriting censorship. Disinformation is another major issue, as social media sites in particular have become hotbeds of fake news, and have led to a situation where different tribes have completely different versions of reality due to the information they see online.\n\nAt a minimum, companies need to have robust processes in place to ensure these decisions are taken properly. Having teams of content moderators with mere seconds to review flagged posts does not meet this bar. Many of the companies involved are highly profitable and worth billions; they need to invest resources proportionate to the problem they have helped create."
template = "block-text"
[[sections]]
template = "block-faq"
title = ""
[[sections.faq]]
answer = "* What is your company’s approach to moderating content? Who inputs into policies around how content is moderated?\n* Is your company transparent about the variables that influence any content moderation algorithms?\n* Does your company allow the promotion and/or monetisation of false or misleading content?"
question = "Some questions to start with"
[[sections.faq]]
answer = "_What you need to know -_ New America has published a [report](https://www.newamerica.org/oti/reports/its-not-just-content-its-business-model/) setting out the influence content platforms can have on democracy, and suggests solutions balancing free speech, privacy and government surveillance concerns.\n\n_The most urgent issue -_ False information broadcast by tech platforms may be hindering progress on all other issues in these pages. Fake news has been [found](http://news.mit.edu/2018/study-twitter-false-news-travels-faster-true-stories-0308) to travel further and faster than true news. Tackling political misinformation is [neglected](https://www.theguardian.com/technology/2021/apr/12/facebook-loophole-state-backed-manipulation) in poorer countries posing less of a PR risk. A recent [investigation](https://secure.avaaz.org/campaign/en/youtube_climate_misinformation/) found that Youtube, despite its commitment to climate action, continues to drive users towards videos containing climate misinformation and allows them to be monetised. This results in greater polarisation and the continuing election of climate deniers as political representatives.\n\n_Who are the big contributors_ - Given their global reach, Alphabet, Facebook and Twitter’s practices have the biggest effects on users. The RDR [ranking](https://rankingdigitalrights.org/index2019/) referred to above also ranks companies on how they approach governance, freedom of expression and privacy."
question = "Further information"
[[sections]]
heading = "Manipulative techniques "
template = "block-heading"
[[sections]]
content = "Many tech companies design to maximise “engagement”, the amount of time spent using their products. Obviously making products so good that people will want to use them again and again is generally a good thing; it becomes an issue when they seek to take advantage of human vulnerabilities to manipulate people to continue using products beyond their rational self-interest. As the CEO of Netflix has [said](https://www.fastcompany.com/40491939/netflix-ceo-reed-hastings-sleep-is-our-competition), its main competitor is not another tech company, but sleep.\n\nThe attention economy has initiated an arms race for people’s attention and time. Unless companies voluntarily step back and impose some self-control, the techniques intended to keep us clicking, buying, watching are only going to become more refined and intrusive. Companies should not seek to maximise the amount of time spent on their sites, but rather should optimise time well spent."
template = "block-text"
[[sections]]
template = "block-faq"
title = ""
[[sections.faq]]
answer = "* What are the metrics your company uses to define success regarding its users? Are those metrics aligned with the users’ own interests?\n* Do your company’s products rely on techniques such as variable rewards, push notifications and continuous streaks that are designed to get users “hooked”? Are children users of these products?"
question = "Some questions to start with"
[[sections.faq]]
answer = "_What you need to know -_ Tristan Harris and his organisation Center for Humane Technology are developing a range of [resources](https://humanetech.com/resources) on this issue and how to design in a more ethical way. There is also a [ledger](https://ledger.humanetech.com/) of research on the harms caused by manipulative tech. For a quick primer on the topic, there is this 1843 [article](https://www.1843magazine.com/features/the-scientists-who-make-apps-addictive) or a [TED talk](https://www.ted.com/talks/tristan_harris_how_a_handful_of_tech_companies_control_billions_of_minds_every_day?language=en) by Harris. A [study](https://arxiv.org/abs/1907.07032) of 11,000 e-commerce sites sets out some common \"dark patterns\" used to steer consumers into making unintended decisions.\n\n_The most urgent issue -_ [Young people](https://www.commonsensemedia.org/technology-addiction) are particularly vulnerable to these techniques which companies increasingly rely upon. While it ultimately falls to parents to ensure their children use products responsibly, it is companies’ choice whether they enable or hinder parents’ efforts."
question = "Further information"
[[sections]]
heading = "Anti-competitive practices"
template = "block-heading"
[[sections]]
image = "/uploads/what-tech-anticompetitive.jpg"
template = "block-image"
[[sections]]
content = "Big tech companies occupy a dominant position in many markets, with search, shopping and social media obvious examples. While that position has enabled them to deliver savings to consumers, it has also enabled them to undermine competition by using their platforms to favour their products over others’; collect and hoard data that, were it more freely available, could be used by other companies to deliver improved services and public goods; and ape or acquire start-ups that pose the smallest threat to their dominance.\n\nThis is primarily an issue that regulation should be stepping in to handle, and some tech companies have received 10-figure fines for anti-competitive behaviour. But by the time policymakers step in irreparable damage has already been done, smaller competitors have been put out of business. Tech companies need to keep their greed in check and not act like a [rapacious AI](https://www.buzzfeednews.com/article/tedchiang/the-real-danger-to-civilization-isnt-ai-its-runaway) programme bent on taking over the world."
template = "block-text"
[[sections]]
template = "block-faq"
title = ""
[[sections.faq]]
answer = "* Has your company erected barriers to customers switching to competing services? For example, is it straightforward for users to move their data to another service provider?\n* Does your company prioritise its own goods on platforms it operates over that of potential competitors?"
question = "Some questions to start with"
[[sections.faq]]
answer = "_What you need to know -_ This is a multi-faceted problem; the form it takes can depend on the type of company involved. For the very biggest companies, Scott Galloway has [set out](https://www.esquire.com/news-politics/a15895746/bust-big-tech-silicon-valley/) many of these reasons and has called for them to be broken up. Specific practices include companies’ approaches to gathering and hoarding [data](https://www.economist.com/briefing/2017/05/06/data-is-giving-rise-to-a-new-economy); copying competitors’ products and then [privileging](https://www.nytimes.com/2019/12/15/technology/amazon-aws-cloud-competition.html) the new product on their platform; introducing [switching costs](https://www.investopedia.com/terms/s/switchingcosts.asp) to prevent customers from easily changing service providers.\n\n_What you can ask for_ - Where it would not interfere with users’ privacy, openly sharing data can both create a more level playing field and lead to much more innovation, as knowledge flowing from data would not be restricted to those companies that generate the data. Allowing data portability, such that users can easily export their playlists, social network connections, etc to another service would similarly encourage competition and improve consumer welfare."
question = "Further information"
[[sections]]
heading = "Bias"
template = "block-heading"
[[sections]]
content = "An increasing number of decisions are being taken or influenced by input from algorithms, from the online advertisements you see to criminal sentencing and parole decisions. These algorithms are generally trained on large amounts of data, which has led to algorithms encoding and perpetuating the disadvantages already faced by certain groups, particularly along the lines of gender and race.\n\nThe companies behind these algorithms need to stop building the failures of the past into the infrastructure of the present and future. Companies must dedicate resources to ensure that algorithms are not producing inequitable outcomes for at-risk groups, and open up these \"black boxes\" to external scrutiny."
template = "block-text"
[[sections]]
template = "block-faq"
title = ""
[[sections.faq]]
answer = "* Are there processes in place to test whether algorithms or AI services developed by your company are producing different outcomes for at-risk groups?\n* Is there third-party research into issues with algorithmic bias in your field? Has your company addressed any issues identified?"
question = "Some questions to start with"
[[sections.faq]]
answer = "_What you need to know -_ There is a wealth of research on how algorithmic bias can lead to inequitable outcomes in different settings - [advertising](https://hbr.org/2019/11/how-targeted-ads-and-dynamic-pricing-can-perpetuate-bias), [criminal sentencing](http://hrlr.law.columbia.edu/hrlr-online/reprogramming-fairness-affirmative-action-in-algorithmic-criminal-sentencing/), [financial services](https://www.brookings.edu/research/reducing-bias-in-ai-based-financial-services/), [recruitment](https://www.weforum.org/agenda/2019/05/ai-assisted-recruitment-is-biased-heres-how-to-beat-it/).\n\n_What to ask for -_ Transparency needs to be a minimum requirement to ensure that other parties are able to access the datasets used to train algorithms and the decisions they are producing to detect and prevent instances of bias."
question = "Further information"

+++
